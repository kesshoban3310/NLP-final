{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4773528",
   "metadata": {},
   "source": [
    "## Infrastructure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80ef223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:00:04.053078Z",
     "iopub.status.busy": "2025-06-09T19:00:04.051903Z",
     "iopub.status.idle": "2025-06-09T19:00:04.060161Z",
     "shell.execute_reply": "2025-06-09T19:00:04.059206Z",
     "shell.execute_reply.started": "2025-06-09T19:00:04.053049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import all the modules\n",
    "import nltk\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import importlib.resources\n",
    "import os\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.google import GoogleModel\n",
    "from pydantic_ai.providers.google import GoogleProvider\n",
    "from pydantic import BaseModel, Field\n",
    "import getpass\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import asyncio\n",
    "import time\n",
    "import re\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, AutoModelForSeq2SeqLM, Seq2SeqTrainer, T5Tokenizer, T5ForConditionalGeneration\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the necessary NLTK resources are downloaded\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "# Check if the api key is set\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
    "\n",
    "# Avoid event loop issues in Jupyter notebooks\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a454b77",
   "metadata": {},
   "source": [
    "## Prepare data for training (one-time setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d1af5",
   "metadata": {},
   "source": [
    "### Trim paragraphs into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0701bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:00:18.051133Z",
     "iopub.status.busy": "2025-06-09T19:00:18.050450Z",
     "iopub.status.idle": "2025-06-09T19:00:35.542900Z",
     "shell.execute_reply": "2025-06-09T19:00:35.539110Z",
     "shell.execute_reply.started": "2025-06-09T19:00:18.051108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f50832b14e1408dbfd151fedb2ad825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77f89275b0847a7ab19e8f094b41e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e17b1afb5643d9833f40da71bba903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6648b861df1b4b4cb4b77e2829f302a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/13.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dd9a9395cf4ce2af6522af71f5d52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f930318ef014f2285a394c8dbf398d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8204c0323e494bb0b11f6bd7f8d712c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff163cc92684c5ab1b1e411361a9f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 50000\n",
      "Sample sentences: ['For a particular post, also take notes from existing and previous post holders.', 'The highly anticipated PBS Kids in the Park festival is tomorrow, Saturday, June 21.', 'Taliesin almost beat it out because of that issue.', 'Zinc includes 285,000 tonnes of refined zinc and 595,000 tonnes of zinc contained in concentrates.', 'Our Cartridges for Epson Expression Premium XP700 are great value with super fast delivery!']\n"
     ]
    }
   ],
   "source": [
    "# Load the raw dataset\n",
    "dataset = load_dataset(\"brando/small-c4-dataset\")\n",
    "dataset = concatenate_datasets(\n",
    "    [dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]]\n",
    ")\n",
    "\n",
    "# Split text into sentences\n",
    "sentences = []\n",
    "for data in tqdm(dataset):\n",
    "    text = data[\"text\"]\n",
    "    for sentence in nltk.tokenize.sent_tokenize(text, language=\"english\"):\n",
    "        sentence_length = len(sentence.strip())\n",
    "        if sentence_length < 50 or sentence_length > 100:\n",
    "            continue\n",
    "        if not re.match(r\"^[a-zA-Z0-9.,!? '\\\"]*$\", sentence):\n",
    "            continue\n",
    "        sentences.append(sentence)\n",
    "sentences = random.sample(sentences, 50000)\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "print(f\"Sample sentences: {sentences[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0744a1",
   "metadata": {},
   "source": [
    "### Generate training data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e59fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b6a27626e947949c97f78edfd82eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180dc724c41b47f1b82052c57255c4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing batch 142: 'UnexpectedModelBehavior' object has no attribute 'output'\n",
      "Error processing batch 318: 'UnexpectedModelBehavior' object has no attribute 'output'\n",
      "Error processing batch 473: 'UnexpectedModelBehavior' object has no attribute 'output'\n",
      "Error processing batch 798: 'UnexpectedModelBehavior' object has no attribute 'output'\n",
      "Error processing batch 928: 'UnexpectedModelBehavior' object has no attribute 'output'\n"
     ]
    }
   ],
   "source": [
    "# Define the Pydantic model for the antithesis generation\n",
    "class Antithesis(BaseModel):\n",
    "    result: str = Field(..., description=\"The antithesis of the original sentence.\")\n",
    "    reasoning: str = Field(\n",
    "        ..., description=\"The reasoning behind the antithesis generation.\"\n",
    "    )\n",
    "\n",
    "# Initialize the LLM agent\n",
    "model = GoogleModel(\"gemini-2.0-flash\", provider=GoogleProvider())\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    output_type=Antithesis,\n",
    "    system_prompt=importlib.resources.read_text(\"prompts\", \"generate_antithesis.txt\"),\n",
    ")\n",
    "\n",
    "# Function to generate antithesis for a given sentence\n",
    "coroutines = []\n",
    "for sentence in tqdm(sentences):\n",
    "    coroutines.append(\n",
    "        agent.run(f\"Generate an antithesis for the following sentence: {sentence}\")\n",
    "    )\n",
    "\n",
    "# Run all the coroutines concurrently\n",
    "dataset = {\"sentence\": [], \"antithesis\": []}\n",
    "for i in tqdm(range(0, len(coroutines), 50)):\n",
    "    coroutines_batch = coroutines[i : i + 50]\n",
    "    sentences_batch = sentences[i : i + 50]\n",
    "    try:\n",
    "        antithesis_batch = asyncio.run(\n",
    "            asyncio.gather(*coroutines_batch, return_exceptions=True)\n",
    "        )\n",
    "        antithesis_batch = [result.output.result for result in antithesis_batch]\n",
    "        dataset[\"sentence\"].extend(sentences_batch)\n",
    "        dataset[\"antithesis\"].extend(antithesis_batch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i // 50}: {e}\")\n",
    "        continue\n",
    "    time.sleep(2)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.to_csv(\"data/antithesis_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42243d",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5bd67",
   "metadata": {},
   "source": [
    "### Load the training data and split it into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435704e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:00:46.979951Z",
     "iopub.status.busy": "2025-06-09T19:00:46.979380Z",
     "iopub.status.idle": "2025-06-09T19:00:47.356242Z",
     "shell.execute_reply": "2025-06-09T19:00:47.355498Z",
     "shell.execute_reply.started": "2025-06-09T19:00:46.979928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 39797, Test size: 9950\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "dataset = pd.read_csv(\"data/antithesis_dataset.csv\")\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "print(f\"Train size: {len(dataset['train'])}, Test size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876e4ac",
   "metadata": {},
   "source": [
    "### Tokenize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deaba6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:00:50.070782Z",
     "iopub.status.busy": "2025-06-09T19:00:50.070518Z",
     "iopub.status.idle": "2025-06-09T19:00:56.202814Z",
     "shell.execute_reply": "2025-06-09T19:00:56.202194Z",
     "shell.execute_reply.started": "2025-06-09T19:00:50.070762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75365bf5e35e44edbecd708ad964adee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45db2e793c154301ac5c19043bf340f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657a4ea4a52145d69594ac44690c9bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a702d1dba3b4a04a88c2b3bcd0db8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39797 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb4b2e979fd4c59ab7e7e5771fb91e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the prefix and tokenizer for the T5 model\n",
    "prefix = \"antithesis : \"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Function to tokenize the dataset\n",
    "def tokenize(data):\n",
    "    inputs = [prefix + sentence for sentence in data[\"sentence\"]]\n",
    "    targets = [antithesis for antithesis in data[\"antithesis\"]]\n",
    "    return tokenizer(inputs, text_target=targets, max_length=512, truncation=True)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f83812",
   "metadata": {},
   "source": [
    "### Define the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c287a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:00:58.821073Z",
     "iopub.status.busy": "2025-06-09T19:00:58.820349Z",
     "iopub.status.idle": "2025-06-09T19:00:59.252055Z",
     "shell.execute_reply": "2025-06-09T19:00:59.251455Z",
     "shell.execute_reply.started": "2025-06-09T19:00:58.821048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1902961f96fc471a822785dc7d59e5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the evaluation metric\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# Function to postprocess the text for evaluation\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "# Function to compute the evaluation metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    preds_sanitized = np.where(preds < 0, tokenizer.pad_token_id, preds)\n",
    "    decoded_preds = tokenizer.batch_decode(preds_sanitized, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred_seq != tokenizer.pad_token_id) for pred_seq in preds_sanitized]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2872167",
   "metadata": {},
   "source": [
    "### Define model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38084ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:01:03.216718Z",
     "iopub.status.busy": "2025-06-09T19:01:03.215219Z",
     "iopub.status.idle": "2025-06-09T19:01:05.478097Z",
     "shell.execute_reply": "2025-06-09T19:01:05.477463Z",
     "shell.execute_reply.started": "2025-06-09T19:01:03.216685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4571cc6965742489f74c70c150f29fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8e82e75f3042d19eddc3056a2daef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f0b48ff4ef41738a3c9f3f13a0d18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a data collator for the T5 model\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=\"t5-small\")\n",
    "\n",
    "# Create training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"antithesis_finetuned_checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create the model for training\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de9792",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361bc452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:01:10.511123Z",
     "iopub.status.busy": "2025-06-09T19:01:10.510626Z",
     "iopub.status.idle": "2025-06-09T19:15:39.353784Z",
     "shell.execute_reply": "2025-06-09T19:15:39.353174Z",
     "shell.execute_reply.started": "2025-06-09T19:01:10.511101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3732' max='3732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3732/3732 14:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.230800</td>\n",
       "      <td>1.962099</td>\n",
       "      <td>21.676100</td>\n",
       "      <td>17.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.921400</td>\n",
       "      <td>1.861403</td>\n",
       "      <td>22.954800</td>\n",
       "      <td>17.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.679200</td>\n",
       "      <td>1.843200</td>\n",
       "      <td>23.514900</td>\n",
       "      <td>17.064800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the T5 model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model(\"antithesis_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246e600",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aae0e0-a17b-4378-9ff1-3cefde1f2294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:38:28.065356Z",
     "iopub.status.busy": "2025-06-09T19:38:28.065088Z",
     "iopub.status.idle": "2025-06-09T19:38:30.003878Z",
     "shell.execute_reply": "2025-06-09T19:38:30.003252Z",
     "shell.execute_reply.started": "2025-06-09T19:38:28.065340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Love builds strong bridges.\n",
      "Antithesis: Hate destroys weak bridges\n",
      "\n",
      "Original: The sun shines brightly.\n",
      "Antithesis: The moon darkens darkly\n",
      "\n",
      "Original: Donald Trump is insane.\n",
      "Antithesis: Donald Trump is wise\n",
      "\n",
      "Original: High mountains are always covered in snow.\n",
      "Antithesis: Low mountains are never exposed to sunshine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "model_path = \"antithesis_finetuned\"\n",
    "prefix = \"antithesis : \"\n",
    "\n",
    "# Define tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Function to generate antithesis for a given sentence\n",
    "def generate_antithesis(sentence):\n",
    "    input_text = prefix + sentence\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    output_ids = model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True, no_repeat_ngram_size=2)\n",
    "    antithesis = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return antithesis\n",
    "\n",
    "# Test the given text\n",
    "texts = [\n",
    "    \"Love builds strong bridges.\",\n",
    "    \"The sun shines brightly.\",\n",
    "    \"Donald Trump is insane.\",\n",
    "    \"High mountains are always covered in snow.\"\n",
    "]\n",
    "for text in texts:\n",
    "    antithesis = generate_antithesis(text)\n",
    "    print(f\"Original: {text}\\nAntithesis: {antithesis}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aaa526-654e-4c98-b477-d3af6fd2572a",
   "metadata": {},
   "source": [
    "## Evaluate the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89718df0-4502-4408-be20-9d50de3b5bdc",
   "metadata": {},
   "source": [
    "### Define the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2bc9a-7360-4003-9478-9a424422b04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:29:51.421447Z",
     "iopub.status.busy": "2025-06-09T19:29:51.420805Z",
     "iopub.status.idle": "2025-06-09T19:29:51.480499Z",
     "shell.execute_reply": "2025-06-09T19:29:51.479897Z",
     "shell.execute_reply.started": "2025-06-09T19:29:51.421425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the Pydantic model for the score\n",
    "class Score(BaseModel):\n",
    "    score: float = Field(..., description=\"The score of the antithesis generation.\")\n",
    "    explanation: str = Field(..., description=\"The explanation of the score.\")\n",
    "\n",
    "\n",
    "# Initialize the LLM agent\n",
    "agent = Agent(\n",
    "    model=GoogleModel(\"gemini-2.0-flash\", provider=GoogleProvider()),\n",
    "    output_type=Score,\n",
    "    system_prompt=importlib.resources.read_text(\"prompts\", \"evaluate_antithesis.txt\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Function to evaluate the antithesis generation\n",
    "async def evaluate_antithesis(sentence, antithesis):\n",
    "    prompt = f\"Evaluate the score quantifies how perfectly they achieve structural antithesis between sentence1 and sentence2.\\n\\n\"\n",
    "    prompt += f\"sentence1: {sentence}\\n\"\n",
    "    prompt += f\"sentence2: {antithesis}\\n\"\n",
    "    result = await agent.run(prompt)\n",
    "    return result.output.score, result.output.explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0a48f-78b7-4ab3-bd1c-121663f001bc",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9936939f-6394-48b1-b630-9c36700b24d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:29:55.394429Z",
     "iopub.status.busy": "2025-06-09T19:29:55.394174Z",
     "iopub.status.idle": "2025-06-09T19:35:00.749700Z",
     "shell.execute_reply": "2025-06-09T19:35:00.748950Z",
     "shell.execute_reply.started": "2025-06-09T19:29:55.394411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c784f7291a14b5eab57426a303d17d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for the finetuned model: 0.7785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feea4ec7b724a378fac64a2b08c2ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for the original model: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the antithesis generation on a small evaluation set\n",
    "evaluation_set = random.sample(dataset[\"test\"].to_list(), 100)\n",
    "\n",
    "# Run the evaluation for the finetuned model\n",
    "average_score = 0\n",
    "for data in tqdm(evaluation_set):\n",
    "    sentence = data[\"sentence\"]\n",
    "    antithesis = generate_antithesis(sentence)\n",
    "    score, explanation = asyncio.run(evaluate_antithesis(sentence, antithesis))\n",
    "    average_score += score / len(evaluation_set)\n",
    "print(f\"Average score for the finetuned model: {average_score:.4f}\")\n",
    "\n",
    "# Run the evaluation for the original model\n",
    "average_score = 0\n",
    "for data in tqdm(evaluation_set):\n",
    "    sentence = data[\"sentence\"]\n",
    "    antithesis = data[\"antithesis\"]\n",
    "    score, explanation = asyncio.run(evaluate_antithesis(sentence, antithesis))\n",
    "    average_score += score / len(evaluation_set)\n",
    "print(f\"Average score for the original model: {average_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7624365,
     "sourceId": 12109831,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7625729,
     "sourceId": 12111827,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
